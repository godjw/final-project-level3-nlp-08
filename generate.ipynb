{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # args = parse_args()\n",
    "\n",
    "    # model_path = args.model_name_or_path\n",
    "    model_path = \"/opt/ml/outputs\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "    # text = args.prompt_text\n",
    "    text = \"청계산 셰르파\"\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    # Check generation time\n",
    "    start = time.time()\n",
    "    gen_ids = model.generate(\n",
    "        torch.tensor([input_ids]),\n",
    "        max_length=64,\n",
    "        repetition_penalty=2.0,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        # num_beams=5,\n",
    "        do_sample=True,\n",
    "        top_k=30,\n",
    "        top_p=0.95,\n",
    "        use_cache=True,\n",
    "    )\n",
    "    generated_text = tokenizer.decode(gen_ids[0, :].tolist())\n",
    "    end = time.time()\n",
    "\n",
    "    print(generated_text)\n",
    "    print(f\"{end - start:.5f} sec\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
